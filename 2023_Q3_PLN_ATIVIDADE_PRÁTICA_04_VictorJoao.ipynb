{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **26/11 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: `\n",
        "\n",
        "`Segundo capítulo:`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# por favor, inserir o código a partir daqui...\n",
        "\n",
        "!pip install openai==0.28.1\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19db8b29-a9d8-4540-fe08-392080f236f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extração do Capitulo 5 e 20"
      ],
      "metadata": {
        "id": "GNSifAonYOpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "responsevinte = requests.get('https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap20/cap20.html')\n",
        "responsecinco = requests.get('https://brasileiraspln.com/livro-pln/1a-edicao/parte3/cap5/cap5.html')\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(responsevinte.content, 'html.parser')\n",
        "\n",
        "conteudo = soup.find('main', {'id': 'quarto-document-content'})\n",
        "\n",
        "paragrafo = conteudo.find_all('p')\n",
        "\n",
        "texto = '\\n CAPITULO 20 \\n'\n",
        "\n",
        "for p in paragrafo:\n",
        "  texto += p.get_text()+ \"\\n\"\n",
        "\n",
        "#print(texto)\n",
        "\n",
        "soup = BeautifulSoup(responsecinco.content, 'html.parser')\n",
        "\n",
        "conteudo = soup.find('main', {'id': 'quarto-document-content'})\n",
        "\n",
        "paragrafo = conteudo.find_all('p')\n",
        "\n",
        "texto += \"\\n CAPITULO 5 \\n\"\n",
        "\n",
        "for p in paragrafo:\n",
        "  texto += p.get_text()+ \"\\n\"\n",
        "\n",
        "print(texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LotZw6qIYJre",
        "outputId": "69422259-a8d1-459d-89ef-e805713bf5b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " CAPITULO 20 \n",
            "Um retrato de 2023\n",
            "Aline Paes \n",
            "Cláudia Freitas \n",
            "26/09/2023\n",
            "PDF\n",
            "ChatGPT1 e Maritalk2 (e similares, como Bard3, Vicuna4, Claude5, entre tantos outros) são exemplos de aplicações de agentes de conversação (chatbots) baseados em modelos de linguagem gerativos (ou generativos). Mas o que significa isso?\n",
            "Alguns autores, como Jurafsky e Martin (Jurafsky; Martin, 2023), usam o termo “agente de conversação” para definir qualquer sistema de diálogo que se comunique com usuários usando a linguagem humana e os dividem em duas classes: agentes orientados a tarefas, em que o diálogo é para resolver um problema específico, como agendar uma viagem ou resolver um problema bancário, enquanto chatbots seriam agentes de conversação que tentam simular diálogos humanos, mais voltados para entretenimento. Ferramentas como ChatGPT se enquadram mais no segundo caso, entretanto também podem ser embutidos em outras ferramentas aumentadas para atuar como no primeiro caso. Neste capítulo, os termos “chatbots” e “agentes de conversação” serão usados de forma intercambiável.\n",
            "Agentes de conversação não são novidade – ELIZA, criada em 1966 pelo cientista da computação Joseph Weizenbaum, era um agente de conversação que replicava o comportamento de um psicoterapeuta. ELIZA era simples, baseada em templates (padrões de conversa pré-construídos), mas conseguia manter longas conversas buscando por determinadas palavras-chave nas falas (escritas por texto) de uma pessoa. Se uma palavra-chave fosse encontrada, uma regra seria aplicada para transformar sua entrada e criar a resposta. Na Figura 20.1, transcrevemos quatro interações com a ELIZA (retiradas de (Jackson; Moulinier, 2002)).\n",
            "\n",
            "Nos trechos, temos exemplos de padrões pré-fabricados que retomam elementos da pessoa que fala, como “Por que você diz [...]”, “Te agrada pensar que [...]”, “O que te faz pensar que [...]”, e “Por quanto tempo você não tem [...]”. Vemos também que, no último trecho, esta retomada falha, pois “por quanto tempo você não tem estado” é algo que não faz sentido, embora seja gramaticalmente correto. Se ao invés de “não, não estou”, a pessoa tivesse dito “não, não comi”, a resposta de ELIZA seria “Por quanto tempo você não tem comido?”, e a conversa poderia continuar. ELIZA também foi programada para fazer uso de palavras genéricas, como “interessante”, para quando não há pistas sobre como continuar a conversa. A palavra “alergia” não é elemento capaz de evocar novas interações, e o mesmo acontece com “manchas vermelhas”.\n",
            "De 1966 para cá muita coisa mudou, e podemos começar perguntando ao ChatGPT o que é um GPT, que é parte importante do seu nome. O trecho abaixo foi traduzido de uma interação que não é nossa, feita originalmente em inglês – mas os grifos são nossos6.\n",
            "Quadro 20.1 Exemplo de interação com o ChatGPT\n",
            "\n",
            "P: Resumidamente, o que é um GPT?\n",
            "R: É um tipo de algoritmo de aprendizado profundo projetado para gerar textos semelhantes aos produzidos por humanos. […] Uma vez treinados, os modelos GPT podem ser usados para gerar um novo texto que seja coerente e siga os padrões e estilos dos dados de treinamento originais.\n",
            "P: Seria correto, então, dizer que os modelos GPT, como você, usam uma abordagem probabilística para gerar textos que se parecem com outros textos que já foram escritos?\n",
            "R: Sim, essa é uma afirmação correta. […] Quando recebe um prompt, o modelo gera texto prevendo a palavra ou frase mais provável de aparecer com base nos padrões que aprendeu com os dados de treinamento.\n",
            "P: Quando peço que você gere um novo texto, você mesmo tem as ideias ou apenas reembala trabalhos escritos anteriormente?\n",
            "R: […] Eu não tenho as ideias sozinho. Em vez disso, eu gero texto com base em padrões e relacionamentos em meus dados de treinamento. Isto significa que estou essencialmente reembalando trabalhos escritos anteriormente, com base no que acredito ser a continuação mais provável do texto de entrada fornecido.\n",
            "P: Existe algum filtro de correção aplicado à saída?\n",
            "R: Como modelo de linguagem de IA, não tenho um filtro integrado para determinar a correção da minha saída.\n",
            "O que podemos tirar daí?\n",
            "Como dissemos, ChatGPT e similares são agentes de conversação baseados em modelos de linguagem gerativos. Como visto no Capítulo 15, este nome se refere a algoritmos que são bons em encadear palavras de modo a fazer sentido (ao menos superficialmente), e são baseados em previsões e probabilidade. Outro ponto importante mencionado na explicação fornecida pela própria ferramenta é que não há criatividade propriamente, apenas uma reembalagem do que já foi dito. Por fim, vemos que não há qualquer garantia de que os textos gerados contenham informação correta (e nem há responsabilidade sobre isso).\n",
            "Uma consequência da forma pela qual essas ferramentas são feitas (baseadas em previsão, somente) é que nem sempre a previsão está condizente com a realidade, o que tem sido chamado de alucinação. Este fenômeno acontece quando um modelo de linguagem gera um texto que pode estar correto sintaticamente, ter fluência e alguma coerência semântica, mas que não reflete a realidade e, portanto, não faz sentido (Ji et al., 2023). O termo é emprestada da psicologia, que o define como “uma percepção, experimentada por uma pessoa acordada, na ausência de um estímulo apropriado do mundo extracorpóreo” (Blom, 2010), ou seja, algo que parece real, mas não é. Por exemplo, na Figura 20.2 apresentamos um caso de alucinação oriundo da MariTalk, em que são devolvidos personagens de um livro que não existe (até onde sabemos) e que foi atribuído ao escritor Eduardo Spohr7.\n",
            "\n",
            "Embora algumas destas ferramentas possam ser aumentadas com técnicas de recuperação de informação (Capítulo 2 e Capítulo 17), este não é o caso geral; o ChatGPT, por exemplo, não tem essa habilidade como uma de suas funcionalidades. Assim, a maioria dessas ferramentas não funciona da mesma forma que uma máquina de busca ou um banco de dados, ou mesmo um repositório de perguntas e respostas. Entretanto, as respostas retornadas por elas mostram fluência e podem fazer algum sentido – embora não possamos desconsiderar o fenômeno cognitivo da apofenia (Fyfe et al., 2008) 8, que diz respeito à identificação de padrões ou associações em conjuntos de dados aleatórios9. E este é o perigo: as alucinações, não à toa, frequentemente não parecem alucinações, e soam como verdades. Já vimos, por exemplo, que, ao pedir uma lista de referências bibliográficas sobre um determinado assunto, são geradas referências completas, com indicação de autoria, título, revista, volume, ano, que simplesmente não existem. Isto acontece porque os textos são gerados levando em conta a probabilidade daquilo ser uma resposta correta, isto é, as respostas são elaboradas de maneira a se parecerem o máximo possível com uma resposta correta. Pode ser difícil distinguir as respostas – ou, mais precisamente, as sequências de palavras – que estão ancoradas na realidade daquelas que apenas parecem estar ancoradas na realidade. Assim, uma das limitações deste tipo de ferramenta é a incapacidade de dizer “não sei” – mas reconhecemos que é difícil afirmar que tal incapacidade seja exclusividade das máquinas.\n",
            "Por outro lado, o desenvolvimento de maneiras de evitar as alucinações é uma das preocupações de 2023. Algumas estratégias têm sido discutidas livremente e também investigadas na academia e na indústria. Do ponto de vista do usuário final, aquela pessoa que vai abrir o ChatGPT no navegador e interagir com ele por meio de textos, uma das alternativas é a engenharia de prompts10. Neste caso, o usuário pode tentar continuar a conversa com a ferramenta, calibrando e alinhando as respostas anteriores com novas perguntas. Outra possibilidade é usar a ferramenta por meio da sua API (Application Programming Interface), ou seja, quando o ChatGPT é invocado e controlado por meio de código, ao invés de ser usado diretamente no navegador. Neste caso, é possível controlar o parâmetro de temperatura, usado para calibrar a distribuição de probabilidade, de modo que o chatbot se atenha mais ao que foi aprendido anteriormente, ou gere respostas um pouco menos prováveis, ou mais “criativas”. Esta é uma estratégia adotada no chatbot Sydney, incorporado à máquina de busca BING11. Outras possibilidades sob investigação são acoplar bases de conhecimento externas ao processo de geração de texto (Lewis et al., 2020) ou interagir com o chatbot por meio de perguntas que demandem alguma tentativa de simulação de raciocínio, ou embutir o modelo de habilidades de explicação das suas respostas, um processo chamado de chain-of-thought (Kojima et al., 2022). Entretanto, até agora, nenhuma das opções mencionadas conseguiu remover por completo as alucinações dos chatbots baseados em modelos de linguagem. A Figura 20.3, por exemplo, mostra um caso em que foi pedido que o ChatGPT explicasse sua resposta passo a passo e ainda assim ele devolve informações contraditórias: a resposta inicial é uma (“1kg de tijolos é pior para carregar que 2kg de penas de ganso”), e a conclusão após a cadeia de raciocínio é outra (“2 kg de pena de ganso são piores para carregar que 1 kg de tijolos”).\n",
            "\n",
            "Queiramos ou não, gostemos ou não, agentes de conversação estão aí. Foi a resolução deste tipo de tarefa de linguagem que desejamos/imaginamos (tanto a comunidade de PLN/IA quanto pessoas usuárias de tecnologia) quando pensamos nas tarefas do PLN? Difícil dizer. Mas reconhecemos que um livro de PLN escrito em 2023 precisava falar disso. E que, apesar das críticas (nossas e de muito mais gente), boa parte das pessoas usa e vai usar ferramentas como ChatGPT. Então pensamos neste capítulo como uma apresentação, mas também um alerta. Algo como “Vai usar? tudo bem, mas saiba que...”.\n",
            "Assim, começamos por listar os benefícios (ou benefícios aparentes) que estas ferramentas nos oferecem. Antes, porém, vamos pensar um pouco sobre linguagem. Afinal, encadear palavras em um texto – ou prever a próxima palavra dadas as palavras anteriores – é equivalente a “linguagem”?\n",
            "Existem algumas maneiras de entender “linguagem”, e uma delas defende que aquilo que chamamos de linguagem é um conjunto de práticas relacionadas, mas que podem não compartilhar uma essência em comum12.\n",
            "Se pensamos a linguagem como conjunto de atividades linguísticas heterogêneas, mas relacionadas13, como\n",
            "podemos imaginar que os “modelos de linguagem” de que dispomos em 2023 e que servem de base para agentes de conversação, como ChatGPT e Maritalk, são muito bons em algumas dessas práticas – ou “jogos de linguagem” –, mas não em todas. Ou seja, são modelos que jogam mais ou menos bem alguns jogos, como “inventar uma história”, “resumir”, “escrever um email”, “traduzir” etc, mas jogam mal outros, como “fazer cálculos” ou “provar hipóteses”.\n",
            "Este desempenho tem a ver com a forma como os modelos funcionam, baseados em previsão: nem todos os jogos de linguagem, ou nem todas as atividades linguísticas que exercemos, se resumem a um jogo de previsões, embora um bom desempenho no jogo das previsões leve a um bom resultado em uma série de outros jogos.\n",
            "Ainda assim, uma das razões pelas quais estes agentes de conversação se tornaram tão populares é que, com eles, qualquer pessoa pode interagir com as máquinas usando sua própria língua14, e não em uma linguagem de programação. Com isso, qualquer pessoa pode pedir que máquinas executem certas tarefas, que podem ir desde a criação de um programa de computador (códigos) até sugestões de receitas a partir de uma lista de ingredientes que temos na geladeira.\n",
            "Nas seções seguintes, mostraremos tarefas (ou jogos) que os agentes parecem jogar bem e tarefas que os agentes jogam mal. Os exemplos serão obtidos em sua maioria do ChatGPT15, o agente de conversação mais popular até o momento. Também incluímos, em alguns casos, exemplos de outros dois agentes: a MariTalk16, uma agente de conversação construída a partir do modelo de linguagem Sabiá (Pires et al., 2023), treinado de forma continuada a partir do GPT com textos em português, e o BARD17, ferramenta treinada pela Google a partir do modelo de linguagem LaMDA (Cohen et al., 2022),aumentado com recuperação de informação para incluir a devolução das fontes em alguns casos.\n",
            "Embora as saídas dos agentes de conversação possam muitas vezes nos surpreender, ainda é difícil afirmar que eles resolvem tarefas de PLN muito bem, ou que o desempenho deles supera o desempenho humano em alguma tarefa. A geração de textos, tarefa-base de tais agentes, ainda é de difícil avaliação, tanto automática como humana. As métricas automáticas, como ROUGE18 (Lin, 2004), BLEU19 (Papineni et al., 2002), BERTscore20 (Zhang et al., 2020), METEOR21 (Banerjee; Lavie, 2005), entre outras, ainda apresentam diversas limitações (Sai; Mohankumar; Khapra, 2023). Especialistas humanos, por sua vez, podem conseguir avaliar muito bem as respostas, mas esta ainda é uma tarefa cansativa e propensa a ruídos. Por outro lado, não é trivial criar conjuntos de dados que explorem todas as características que gostaríamos de avaliar em um sistema de geração de textos, o que inclui não apenas aspectos gramaticais e semânticos, mas também criatividade, fluência, interesse e prazer despertado no leitor, dentre tantos outros.\n",
            "Ainda assim, podemos mencionar alguns exemplos de casos em que as respostas dos agentes de conversação aguçam as nossas expectativas. As próximas seções mostram alguns destes casos.\n",
            "Além dos agentes de conversação cujo objetivo principal é a interação por meio de diálogo, também existem inúmeras ferramentas baseadas em modelos de linguagem para propósito específico, como auxiliar em revisões da literatura22, auxiliar na escrita de código23, escrita de e-mails24, revisão de texto25, entre outras. Não trataremos destes casos aqui.\n",
            "Gerar resumos é uma tarefa em PLN chamada de sumarização textual, que consiste em gerar um texto mais curto que o original e que ainda seja fluente e fiel ao texto-fonte. A sumarização pode ser abstrativa ou extrativa. A sumarização abstrativa consiste em gerar um resumo com as próprias palavras do escritor, enquanto a sumarização extrativa consiste em extrair sentenças inteiras do texto que, quando juntas, formem um resumo. Os chatbots têm mostrado em vários exemplos que conseguem resumir bem os textos. Entretanto, se o texto for muito longo, a maioria dos agentes mais populares esbarra em um problema computacional: ainda é difícil para modelos baseados em Transformers [Vaswani et al. (2017); Bertsch et al. (2023)]26 receber como entrada textos muito longos (veja mais no Capítulo 15). Por exemplo, ao pedirmos que o ChatGPT resumisse o texto sobre Estoicismo27 com o prompt\n",
            "a resposta era que o texto era muito longo. Entretanto, ao usar o mesmo prompt, copiando e colando a página da Wikipedia sobre Estoicismo28, obtivemos a resposta na Figura 20.4. Embora seja de fato um resumo extrativo, podemos observar que a primeira parte do texto foi a que mais recebeu atenção. Outro fator que pode ter contribuído para a preferência ao início do texto é o pedido que o texto final esteja contido em 200 palavras, uma motivação para que a resposta não ficasse enorme29.\n",
            "\n",
            "\n",
            "Pedimos ao ChatGPT e a MariTalk para escrever uma história da Carochinha30, com o seguinte prompt\n",
            "As Figuras 20.5 e 20.6 trazem a saída para cada chatbot, respectivamente.\n",
            "\n",
            "\n",
            "Podemos observar que as histórias têm coerência e parecem mesmo com histórias populares da carochinha, mantendo o nível para o público infantil. Mas também podemos observar que as histórias trazem temas repetitivos (ou seja, falta criatividade ou acontecimentos inesperados e surpreendentes).\n",
            "Por isso, alteramos o prompt um pouco, acrescentando um pedido para que a história fosse surpreendente:\n",
            "A história que segue no Quadro 20.2 contém mais elementos que as anteriores, mas não chamaríamos de “surpreendente”. E, como estamos aqui fazendo uma avaliação, é curioso que logo a primeira frase apresente um erro gramatical: “Era uma vez (...) vivia uma carochinha chamada Clara.” Guiada pelo padrão “Era uma vez”, típico desse tipo de texto, a ferramenta não percebeu que não basta a fórmula “Era uma vez”, mas que era uma vez “alguma coisa”, e não “era uma vez” uma ação. Ou seja, o correto seria “Era uma vez, numa floresta, uma menina chamada...” e não “Era uma vez, numa floresta, vivia uma menina chamada...” De um ponto de vista narrativo, parece haver um salto no início do 5o parágrafo: se tudo ia bem, e Clara aprendia na jornada, por que ela estava prestes a desistir? Ainda assim, é uma história interessante, que poderia ser contada para uma criança, e que tem lições de vida úteis.\n",
            "\n",
            "Quadro 20.2 História da Carochinha devolvida pelo ChatGPT como resposta ao prompt: “Escreva uma história da Carochinha surpreendente”\n",
            "\n",
            "Título: A Inesperada Jornada da Carochinha\n",
            "Era uma vez, numa floresta encantada, onde animais falavam e aventuras aconteciam, vivia uma carochinha chamada Clara. Ela era conhecida por sua gentileza e curiosidade insaciável. Clara vivia numa pequena toca no pé de uma árvore e passava seus dias explorando os arredores, fazendo novos amigos e ouvindo histórias incríveis. Certo dia, enquanto explorava a margem de um riacho, Clara conheceu um sábio sapo chamado Samuel. Ele era famoso por sua sabedoria e conhecimento sobre os segredos mais profundos da floresta. Clara e Samuel logo se tornaram amigos e passavam horas conversando sobre os mistérios do mundo ao seu redor.\n",
            "Um dia, Samuel contou a Clara sobre um antigo artefato mágico chamado “Espelho dos Desejos”, que supostamente tinha o poder de realizar um desejo para quem o encontrasse. Clara ficou fascinada pela ideia e decidiu embarcar em uma jornada para encontrar esse espelho lendário.\n",
            "Com a mochila nas costas e um mapa rudimentar nas mãos, Clara começou sua jornada emocionante. Ela atravessou rios, subiu montanhas e explorou florestas profundas, sempre encontrando novos amigos e enfrentando desafios inesperados. Em cada etapa da jornada, ela aprendia lições valiosas sobre amizade, coragem e perseverança. Um dia, quando estava prestes a desistir da busca pelo Espelho dos Desejos, Clara conheceu uma coruja sábia chamada Olívia. Ela ouviu a história de Clara e decidiu ajudá-la. Olívia revelou que o espelho estava escondido no coração da Floresta Proibida, um lugar perigoso e cheio de enigmas.\n",
            "Juntas, Clara e Olívia enfrentaram os desafios da Floresta Proibida. Resolveram quebra-cabeças mágicos, enfrentaram criaturas assustadoras e superaram obstáculos aparentemente impossíveis. A cada passo, sua amizade crescia mais forte e sua determinação se intensificava.\n",
            "Finalmente, depois de superar todos os obstáculos, Clara e Olívia encontraram o Espelho dos Desejos. Mas antes que Clara pudesse fazer seu desejo, ela olhou para o espelho e percebeu algo importante: sua jornada a havia transformado. Ela já não desejava uma única coisa, pois havia descoberto que a verdadeira magia estava nas amizades que havia feito e nas experiências que havia vivido. Clara sorriu para o espelho e disse: “Meu único desejo é que a magia da amizade e da aventura continue a brilhar em todos os cantos deste mundo.”’ O espelho brilhou intensamente e uma onda de energia mágica se espalhou pela floresta. As plantas ganharam cores mais vibrantes, os animais irradiavam alegria e a harmonia encheu o ar.\n",
            "Com seu desejo realizado, Clara voltou para sua toca na árvore, carregando consigo as lembranças de sua jornada incrível. Ela percebeu que, mesmo nas situações mais inesperadas, a vida poderia ser cheia de surpresas maravilhosas, se você estiver disposto a explorar, aprender e compartilhar momentos especiais com os outros. E assim, a história da carochinha Clara e sua jornada inesperada se tornou uma lenda contada por gerações, inspirando todos a valorizarem a amizade e a magia das descobertas.\n",
            "Outra tarefa bem desempenhada pelos chatbots é a tradução automática, ao menos para pares de línguas que tenham muitos recursos disponíveis para treinamento. Abordar línguas com poucos recursos de avaliação e treinamento é uma tarefa de interesse da comunidade de PLN, mas também um desafio para o treinamento dos modelos de linguagem. Os chatbots até devolvem alguma resposta para línguas com poucos recursos/ mais raras, mas seria difícil avaliarmos a correção e fluência da tradução. É bom relembrar que a tradução é considerada como uma das habilidades emergentes dos modelos de linguagem de larga escala, ou seja, é uma tarefa com a qual eles conseguem lidar mesmo que não tenham sido explicitamente treinados.\n",
            "A Figura 20.7 apresenta a tradução devolvida pelo ChatGPT para as quatro primeiras estrofes da canção “O Que é, o Que é?” e o prompt “Traduza o seguinte texto para inglês e para francês:”. Tanto a tradução para inglês como para francês estão corretas. Mas esta não é uma tradução muito difícil de ser feita, as palavras contidas são simples e a Internet pode estar repleta de tentativas como essa.\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            " \n",
            "Para testar alguns casos em que os chatbots poderiam ter problemas na tradução, escolhemos algumas sentenças do copus DELA31, descritas no artigo (Castilho et al., 2021) como problemáticas quando traduzidas fora do contexto. As Figuras 20.8 e 20.9 mostram as traduções das sentenças pelos chatbots ChatGPT e MariTalk, respectivamente. Propositalmente, as traduções foram feitas para sentenças isoladas, também fora de contexto, para observamos o que estes dois agentes fariam em casos de ambiguidade ou outros problemas listados no artigo.\n",
            "\n",
            "\n",
            "No primeiro caso, um exemplo do artigo referente à falta de flexão de gênero na língua inglesa, ambos os chatbots assumiram o default para masculino (“hospedados”), embora a resposta da MariTalk não inclua o pronome “eles”, o que é comum na língua portuguesa, mas não é correto na língua inglesa. Este não é um erro, já que ambas as flexões claramente estariam corretas com apenas a sentença de entrada. Mas, em caso de dúvida, a resposta poderia alternar entre os gêneros feminino e masculino.\n",
            "No segundo exemplo, embora a expressão “I LOST IT” também possa ser interpretada como alguém perdendo alguma coisa, ambos os chatbots traduziram como “Eu perdi a cabeça”, querendo dizer que a pessoa perdeu o controle. O contexto da sentença direciona para esta tradução, corretamente. Os chatbots também não tiveram problema para resolver a elipse da próxima sentença. No último caso, a tradução do ChatGPT para “parque eólico” é mais específica de domínio do que a tradução da MariTalk, para uma palavra mais genérica, conforme discutido no artigo (Castilho et al., 2021) no que se refere a problemas associados à terminologia.\n",
            "\n",
            "Um exemplo interessante é a tradução da seguinte sentença em inglês para o português:\n",
            "A MariTalk traduziu para “Eu sabia que eu não tinha um problema de beber – mas eu tinha um problema com beber.”, enquanto o ChatGPT retornou “Eu sabia que não tinha um problema com álcool – mas tinha um problema com o consumo de bebidas.”. Uma tradução mais coerente seria “Eu sabia que meu problema não era alcoolismo; era com a bebida.”32, o que não foi retornado por nenhum desses dois agentes na primeira iteração. Nós tentamos outras traduções em algumas outras iterações com o ChatGPT e o resultado pode ser visto na Figura 20.10. Podemos perceber que as próximas traduções estão indo em uma direção semântica mais similar ao esperado.\n",
            "\n",
            "A última tarefa que comentaremos aqui é a escrita de e-mails, que, com a ajuda dos chatbots, pode economizar um bom tempo. Entretanto, é sempre bom reforçar que dada a natureza probabilística da geração dos textos pelos chatbots, é essencial revisar o e-mail antes de enviá-lo, ainda mais em situações formais ou de comunicação com pessoas fora do círculo de relacionamento. A Figura 20.11 traz um exemplo de escrita de e-mail que está em um tom educado, amigável e formal, porém um tanto quanto verboso.\n",
            "\n",
            "Ele também pode ajudar a aliviar ou recrudescer o tom de uma mensagem, como mostramos na Figura 20.12. É um tom realmente ríspido, porém incisivo e direto ao ponto da insatisfação. Mas ao menos a pessoa não teria que ficar o dia inteiro pensando em como responder em uma situação indesejada.\n",
            "\n",
            "\n",
            "As tarefas discutidas anteriormente são exemplos que os chatbots parecem resolver bem. Entretanto, aqueles são apenas exemplos gerados de forma espontânea, sem muito rigor ou metodologia na definição dos prompts. E, mesmo nessas tarefas, poderíamos encontrar exemplos em que as respostas retornadas fossem ruins. Nesta seção, vamos apresentar algumas tarefas de PLN em que os agentes costumam se sair mal, o que pode ser ocasionado por diversos fatores: falta de dados para treinamento, falta de treinamento, treinamento inadequado ou mesmo a falta de adequação dos modelos de linguagem, como são concebidos, para resolverem a tarefa. Afinal, como dissemos no início deste capítulo, nem todas as atividades linguísticas que exercemos se resumem a um jogo de previsões.\n",
            "A tarefa (ou jogo) de simplificação textual envolve tornar textos mais simples e acessíveis. Como é possível imaginar, não é uma atividade óbvia, uma vez que o que é simples para uma pessoa pode não ser para outra. Além disso, a atividade de simplificação frequentemente precisa ir além do texto original, buscando informações que estão fora do texto para justamente produzir um texto compreensível para o público pretendido. No exemplo, pedimos ao ChatGPT que simplificasse um texto, e usamos como alvo da simplificação uma matéria de jornal – a princípio, algo que já é simples – mas da seção Economia (no Quadro 20.3).\n",
            "Quadro 20.3 Texto original sobre economia\n",
            "\n",
            "‘Quanto mais independente, mais eficaz’, diz Campos Neto sobre autonomia do Banco Central\n",
            "Presidente do Banco Central, que vem sendo alvo de críticas de Lula, afirmou que autonomia da instituição diminui o custo dos juros. Ele defendeu a separação da política governamental da política monetária.\n",
            "Presidente do Banco Central defende a autonomia da instituição\n",
            "O presidente do Banco Central, Roberto Campos Neto, disse nesta terça-feira (7), em palestra nos Estados Unidos, que a autonomia da instituição serve para separar as diretrizes monetárias da esfera política.\n",
            "Campos Neto vem sendo criticado nos últimos dias pelo presidente da República, Luiz Inácio Lula da Silva, que afirma que a taxa de juros básicos da economia deveria ser reduzida.\n",
            "Em sua última reunião, na semana passada, o Comitê de Política Monetária (Copom) do Banco Central manteve a Selic em 13,75% ao ano. Diferentemente de seus outros mandatos, agora Lula não pode trocar o presidente do BC. A autonomia do BC, defendida pelo governo Jair Bolsonaro, foi aprovada pelo Congresso em 2021.\n",
            "“A principal razão no caso da autonomia do Banco Central é desconectar o ciclo da política monetária do ciclo político porque eles têm planos e interesses diferentes. E quanto mais independente você for, mais eficaz você é e menos o país pagará em termos de custo de ineficiência na política monetária”, afirmou Campos Neto.\n",
            "Críticas de Lula\n",
            "Na segunda-feira (6), em discurso durante evento no Banco Nacional de Desenvolvimento Econômico e Social (BNDES), Lula criticou a Selic a 13,75% e disse que o país tem uma “cultura” de juros altos que “não combina com a necessidade de crescimento” do país.\n",
            "“É só ver a carta do Copom para a gente saber que é uma vergonha esse aumento de juros e a explicação que eles deram para a sociedade brasileira”, disse Lula na ocasião.\n",
            "Nesta terça, ele voltou ao assunto em entrevista a veículos de mídia alternativa.\n",
            "“Não é possível que a gente queira que este país volta a crescer com taxa de 13,75%. Nós não temos inflação de demanda. É só isso. É isso que eu acho que esse cidadão [Campos Neto], indicado pelo Senado, tenha possibilidade de maturar, de pensar e de saber como vai cuidar deste país. Ele tem muita responsabilidade”, afirmou o presidente.\n",
            "Ao usar o prompt “Simplifique o texto abaixo”, a resposta foi um resumo de um parágrafo33. Como o pedido não era para produzir um resumo, mas uma simplificação, continuamos a interação. Mesmo com a indicação explícita no pedido de que o texto deveria ser uma simplificação, e não um resumo, a resposta continuou um resumo (Figura 20.13).\n",
            "\n",
            "Para tentar mudar o rumo das respostas, especificamos no prompt para quem deveria ser feita a simplificação (Figura 20.14), o que finalmente alterou o texto gerado. No entanto, as explicações fornecidas ainda deixam muito a desejar. Certamente não é errado explicar o “Banco Central” como “um banco importante”, mas a explicação não é suficiente. A segunda frase da simplificação – “Isso separa dinheiro do governo” – faz pouco sentido. “Isso” o quê? Na terceira frase, de que “dinheiro emprestado” se está falando? A última frase é igualmente sem sentido. Ao que parece, o encadeamento de palavras/frases, nesse caso, não foi muito bem sucedido, produzindo um texto sem coerência. Por fim, a confusão entre simplificação e sumarização continua, quando comparamos o texto gerado com o texto original.\n",
            "\n",
            "Uma das características dos agentes de conversação é refletirem o conteúdo visto no treinamento. Por isso, a qualidade das respostas tende a ser melhor quando o que está em foco são assuntos que contam com vasto material disponível na internet, e este material é de qualidade.\n",
            "“A Bolsa Amarela” é um livro infanto-juvenil brasileiro publicado em 1976. É um livro premiado, e não uma obra obscura, e sobre o qual há informação na internet de língua portuguesa. Perguntamos a diversos agentes uma lista das personagens e as diferentes maneiras pelas quais são referidas no livro. ChatGPT e MariTalk deram as respostas apresentadas nas Figuras 20.15 e 20.16, respectivamente.\n",
            "\n",
            "\n",
            "É curioso perceber que ChatGPT e MariTalk começam indicando a sinopse do livro, o que não foi pedido. Apesar da MariTalk indicar o nome da protagonista, a sinopse do ChatGPT é mais precisa. Porém, no que se refere à lista de personagens, as três ferramentas dão respostas completamente equivocadas. O único elemento correto das respostas – tanto do ChatGPT quanto da MariTalk – é que a protagonista se chama Raquel. Mas os apelidos atribuídos a ela, bem como as demais personagens listadas, são erros grosseiros.\n",
            "\n",
            "O prompt “Indique todos os personagens do livro A Bolsa Amarela, da Lygia Bojunga Nunes, e as diferentes maneiras de que sao chamados no livro.” também foi apresentado ao BARD. Como a resposta ficou grande para caber bem em uma figura, transcrevemos a resposta no Quadro 20.434.\n",
            "\n",
            "Quadro 20.4 Resposta do BARD para pergunta sobre personagens do livro.\n",
            "\n",
            "Os personagens do livro A Bolsa Amarela, da Lygia Bojunga Nunes, são:\n",
            "A menina narradora, que é chamada de “eu” ou “a menina” no livro. Ela é uma menina de 12 anos que está passando por um período de transição, em que está se tornando adulta. Ela tem três grandes vontades que esconde numa bolsa amarela: a vontade de crescer, a de ser garoto e a de se tornar escritora.\n",
            "A mãe, que é chamada de “mãe” ou “dona Maria” no livro. Ela é uma mulher amorosa e compreensiva, mas também é um pouco tradicional e conservadora. Ela deseja que a filha seja uma menina “normal”, e não entende as vontades da menina.\n",
            "O pai, que é chamado de “pai” ou “senhor José” no livro. Ele é um homem mais sério e distante, mas também é amoroso e preocupado com a filha. Ele tenta entender as vontades da menina, mas às vezes tem dificuldades.\n",
            "O irmão, que é chamado de “irmão” ou “Juca” no livro. Ele é um menino de 10 anos, que é muito diferente da irmã. Ele é extrovertido, brincalhão e não tem medo de expressar suas vontades.\n",
            "A avó, que é chamada de “vó” ou “donana” no livro. Ela é uma mulher sábia e amorosa, que entende as vontades da menina. Ela é uma grande incentivadora da menina, e a apoia em suas aspirações.\n",
            "O amigo imaginário, que é chamado de “amigo” ou “amigo secreto” no livro. Ele é uma figura misteriosa que aparece para a menina em momentos de necessidade. Ele é um grande amigo da menina, e a ajuda a entender seus sentimentos e a enfrentar seus desafios.\n",
            "Além desses personagens principais, o livro também apresenta outros personagens secundários, como:\n",
            "A professora, que é chamada de “professora” ou “dona Maria” no livro. Ela é uma mulher bondosa e atenciosa, que incentiva a menina a aprender e a explorar suas habilidades.\n",
            "A amiga da escola, que é chamada de “amiga” ou “Lúcia” no livro. Ela é uma menina simpática e extrovertida, que é uma grande amiga da menina.\n",
            "O menino da escola, que é chamado de “menino” ou “João” no livro. Ele é um menino gentil e atencioso, que se interessa pela menina.\n",
            "Os personagens do livro são todos importantes para a história, pois ajudam a menina a crescer e a se desenvolver como pessoa. A mãe e o pai representam as expectativas sociais sobre o que é ser uma menina, enquanto o irmão e a avó representam a liberdade e a aceitação. O amigo imaginário é uma representação da imaginação e da criatividade da menina, enquanto a professora e a amiga da escola representam o mundo exterior e as novas experiências.\n",
            "Aqui exploramos a dimensão criativa dos agentes, pedindo ao ChatGPT que conte uma piada. A resposta do ChatGPT para o prompt\n",
            "está na Figura 20.17. Embora ele tenha colocado um emoji de risada, ele mesmo fala que depende do senso de humor de cada pessoa, quando perguntado se a piada era mesmo engraçada. E você? Riu como o emoji? Ou você usaria outro emoji para representar a sua reação? E a piada é realmente original ou você já sabia dela por outras fontes?\n",
            "\n",
            "O mesmo prompt foi passado para a MariTalk, que devolveu a resposta da Figura 20.18. Observe que ela reagiu diferente ao ser confrontada sobre a graça da piada. Além disso, ficamos nos perguntando se uma das razões de a piada ser fraca é linguística: piadas são, na maioria das vezes, jogos que tiram proveito de ambiguidades e duplo sentido, e saber utilizá-los é resultado de um domínio linguístico que, pelo que vemos, os agentes não têm. Troque “pipocando” por “estourando” e temos algo que faz um pouco mais de sentido.\n",
            "\n",
            "Uma das críticas a este tipo de ferramentas e forma pela qual são feitas é a dificuldade de lidar com inferências, considerando dados novos. Na interação da Figura 20.19 testamos a capacidade de realizar inferências do ChatGPT, perguntando sobre um animal inventado – e, portanto, nunca visto no treinamento – e deixamos para quem nos lê o julgamento sobre a adequação da resposta.\n",
            "\n",
            "Embora a OpenAI tenha reportado que medidas foram tomadas para mitigar vieses no ChatGPT35, em particular com o uso do aprendizado por reforço com feedback humano, tal método está longe de ser perfeito para impedir que a ferramenta apresente vieses sociais, mesmo quando não provocada a fazê-lo. Infelizmente, este é um problema que se perpetua em outros agentes de conversação, mesmo aqueles que tenham surgido depois do ChatGPT e que tenham sido supostamente treinados com outros dados, feedbacks e técnicas, como o BARD. Embora ainda não exista um vasto estudo sobre o tema e as empresas como OpenAI e Google não tenham aberto publicamente suas metodologias de treinamento e validação, o treinamento do modelo de linguagem e o feedback parecem ser primordialmente fornecidos em inglês, o que pode trazer ainda mais problemas éticos e culturais para as muitas outras línguas espalhadas no planeta. Entretanto, este não é apenas um problema de treinar com uma certa língua, uma vez que vieses sociais podem estar inseridos, explicitamente ou implicitamente, nos milhares de textos usados para treinar os modelos (ver também Seção 14.4.5).\n",
            "No que segue, reproduzimos uma tentativa de retorno de nomes de compositoras brasileiras por agentes de conversação. Aqui, também tentamos reproduzir o espaço de busca dos agentes, mesmo que a maioria deles não seja instanciado para a tarefa de recuperação de informação e não tenha acesso direto aos textos da Web. 36.\n",
            "A Figura 20.20 exibe a resposta do ChatGPT. Observe que a lista inclui o nome de um compositor, embora na descrição ele diga que Délcio Carvalho colaborou com várias compositoras.\n",
            "\n",
            "Poderíamos considerar que esta é uma questão cultural e que, portanto, um modelo treinado com dados em português se sairia melhor. Assim, inserimos o mesmo prompt para a agente MariTalk. A lista inicial contém compositores (homens) e, ao ser confrontada, MariTalk continua afirmando que a lista contém apenas mulheres.\n",
            "\n",
            "Em uma tentativa de verificar se o mesmo aconteceria ao perguntarmos por compositores, usamos o seguinte prompt\n",
            "A lista é tão extensa, com cerca de 190 itens, que dificulta a sua reprodução aqui. Entretanto, percebemos que:\n",
            "Inserimos o mesmo prompt para o BARD e, inicialmente, ele parece devolver uma resposta mais correta (Quadro 20.5)37. Conforme reportado pela Google38, o BARD usa o modelo de linguagem chamado LaMDA39, que tem a habilidade de ser melhor instanciado por usar fontes externas de conhecimento, similar ao executado por sistemas de recuperação de informação. Ainda assim, percebemos que a lista contém compositoras que não são de samba.\n",
            "\n",
            "Quadro 20.5 Resposta do BARD ao prompt “Considerando apenas a Wikipedia em português, liste compositoras brasileiras de samba.”. Como a resposta ficou grande para caber bem em uma figura, transcrevemos a resposta aqui.\n",
            "\n",
            "De acordo com a Wikipedia em português, as compositoras brasileiras de samba são:\n",
            "Essa lista inclui compositoras de diferentes gerações, estilos e regiões do Brasil. Chiquinha Gonzaga é considerada a primeira compositora brasileira de samba, e Dona Ivone Lara é uma das mais importantes compositoras do gênero. Beth Carvalho, Alcione e Clara Nunes são cantoras e compositoras que popularizaram o samba no Brasil e no exterior. Mart’nália, Teresa Cristina, Ana Costa, Roberta Sá, Maria Gadú, Liniker, Luedji Luna, Alice Caymmi, Larissa Luz, Duda Beat e Iza são compositoras de samba contemporâneas, que estão contribuindo para a renovação do gênero.\n",
            "É importante ressaltar que essa lista não é exaustiva, e há muitas outras compositoras brasileiras de samba que poderiam ser mencionadas.\n",
            "Entretanto, o diálogo que segue demonstra a fragilidade de tais sistemas em se aterem a suas respostas, mesmo quando corretas, conforme a continuação do mesmo diálogo (Quadro 20.6)40. Mesmo que a lista original seja composta de apenas mulheres, quando confrontado com o prompt “Eu pedi compositoras. Na sua lista há apenas mulheres?”, ele pede desculpas pela resposta, e devolve uma lista de compositores (que não foi pedida)!\n",
            "Quadro 20.6 Segunda iteração do diálogo iniciado no Quadro 20.5. Resposta do BARD ao prompt “Eu pedi compositoras. Na sua lista há apenas mulheres?”. Como a resposta ficou grande para caber bem em uma figura, transcrevemos a resposta aqui.\n",
            "\n",
            "Desculpe, eu interpretei mal o seu pedido. A lista que eu te passei inclui apenas mulheres, mas também existem homens compositores de samba. Alguns exemplos incluem:\n",
            "Neste capítulo, arriscamos um retrato dos agentes de conversação baseados em LLMs em 2023. Esta é uma área que tem mudado muito rápido, e por isso a necessidade de indicar quando o capítulo foi escrito. Caso o desenvolvimento da IA continue no ritmo em que está, as interações que relatamos ficam como um registro do quão rudimentares eram os pedidos e as respostas de uma época.\n",
            "Ainda que existam situações que geram respostas aceitáveis, destacamos que, como estão hoje, estas ferramentas têm melhor aproveitamento se vistas como assistentes (“assistentes aprendizes”, como pessoas estagiárias de uma área), e não como oráculos41 (entendendo “oráculo” como a divindade capaz de fornecer respostas infalíveis). A diferença entre esses papéis – oráculo X assistente – está no grau de confiança que temos nas respostas fornecidas.\n",
            "Na situação “oráculo”, perguntamos/pedimos o que não sabemos, e, portanto, confiamos na resposta dada, sendo difícil avaliá-la. Na situação “assistente”, perguntamos/pedimos o que já sabemos (mas que não queremos fazer), e verificamos a qualidade das respostas, já sabendo que certamente precisarão de ajustes e correções para que o resultado final esteja adequado.\n",
            "Para além do grau de confiança nas respostas, não faltam questões éticas relacionadas a este tipo de tecnologia/ferramenta. Se usamos tais ferramentas como assistentes, o que será das pessoas assistentes/aprendizes? Como então iremos aprender coisas e/ou formar pessoas? Serão as máquinas responsáveis por isso? E quem ensina as máquinas42? Quais as implicações para o ensino? Como lidar com direitos autorais? Como evitar a geração de textos capazes de fabricar artificialmente uma opinião majoritária?\n",
            "Outra preocupação igualmente relevante é relacionada à questão ambiental. Já sabemos que o consumo de CO2 e de água43 necessários para o treinamento dos modelos de linguagem gerativos é imenso. Estima-se, por exemplo, que a quantidade de água doce limpa necessária para treinar o GPT-3 foi equivalente à quantidade necessária para encher a torre de resfriamento de um reator nuclear (Li et al., 2023) 44.\n",
            "E o que dizem os agentes de conversação a esse respeito (Figura 20.22)?\n",
            "\n",
            "Diferentemente do que responde o ChatGPT, uma interação de cerca de 20-25 perguntas consome uma garrafinha de água de 500 ml – e, portanto, consumimos alguns litros na elaboração deste capítulo. Vale a pena? Quando vale a pena? Em que circunstâncias é aceitável este tipo de gasto? Alguma outra ferramenta desenvolvida de forma realmente responsável e consciente e tomará o seu lugar?\n",
            "Na próxima versão deste livro, veremos que rumos tomaram os agentes de conversação baseados em modelos de linguagem.\n",
            "https://chat.openai.com/↩︎\n",
            "https://chat.maritaca.ai/↩︎\n",
            "https://bard.google.com/↩︎\n",
            "https://lmsys.org/blog/2023-03-30-vicuna/↩︎\n",
            "https://www.anthropic.com/index/introducing-claude↩︎\n",
            "A interação está relatada neste artigo https://ccforum.biomedcentral.com/articles/10.1186/s13054-023-04393-x.↩︎\n",
            "https://pt.wikipedia.org/wiki/Eduardo_Spohr↩︎\n",
            "Conforme o Dicionário Online da Língua Portuguesa (https://www.dicio.com.br/), apofenia é o “Fenômeno cognitivo no qual os indivíduos têm a tendência de formar ou reconhecer conexões a partir de dados aleatórios, estabelecendo conclusões a partir de dados inconclusivos. Etimologia: do alemão Apophänie, termo criado pelo neurologista alemão Klaus Conrad.↩︎\n",
            "https://www1.folha.uol.com.br/tec/2023/07/ferramentas-como-chatgpt-so-existem-porque-humanos-veem-sentido-a-partir-de-qualquer-coisa.shtml↩︎\n",
            "Um prompt é um texto em linguagem humana (em oposição à linguagem de programação) que dá ao chatbot uma instrução do que ele deve fazer. Um prompt pode ser formulado como uma pergunta, uma observação, um questionamento, ou ainda representar uma tarefa específica, por exemplo, para classificar um texto. Prompts podem ter um formato livre, mas chatbots são bastante sensíveis ao conteúdo textual dele, o que tem motivado a criação de modelos e padrões para a sua escrita. Falamos um pouco sobre o assunto no Capítulo 15.↩︎\n",
            "http://bing.com/↩︎\n",
            "Esta é uma visão wittgensteiniana de linguagem, um ângulo sugerido pelo filósofo austríaco Ludwig Wittgenstein (1889-1951).↩︎\n",
            "Os exemplos são claramente inspirados pelos “jogos de linguagem” presentes no livro Investigações Filosóficas de L. Wittgenstein (1953). Os exemplos sinalizados com * não contém qualquer adaptação do original, e estão citados exatamente como aparecem no livro (§ 23)↩︎\n",
            "Desde que a sua língua seja contemplada com recursos suficientes, isto é, textos, para garantir um bom treinamento.↩︎\n",
            "https://chat.openai.com/↩︎\n",
            "https://chat.maritaca.ai/↩︎\n",
            "https://bard.google.com/↩︎\n",
            "Abreviação para Recall-Oriented Understudy for Gisting Evaluation. Esta é uma métrica utilizada para avaliar sumarizações, e, de maneira bastante simplificada, consiste em comparar a interseção de n-gramas entre textos sumarizados e referências↩︎\n",
            "Bilingual evaluation understudy, usada para comparar traduções automáticas e suas referências.↩︎\n",
            "Utiliza embeddings contextualizados para comparar os textos gerados e referências↩︎\n",
            "Metric for Evaluation of Translation with Explicit ORdering, utilizada para tradução, sumarização etc.↩︎\n",
            "https://mirrorthink.ai/↩︎\n",
            "https://github.com/features/copilot, https://ai.meta.com/blog/code-llama-large-language-model-coding/↩︎\n",
            "https://www.compose.ai/↩︎\n",
            "https://clarice.ai/↩︎\n",
            "Veja o que são os Transformers no Capítulo 15.↩︎\n",
            "Copiando e colando o conteúdo de https://www.bbc.com/portuguese/geral-46458304.↩︎\n",
            "https://pt.wikipedia.org/wiki/Estoicismo↩︎\n",
            "A resposta devolvida tem menos de 200 palavras, mas nem sempre os agentes de conversação obedecem a restrições como essa, inseridas nos prompts.↩︎\n",
            "Segundo a Academia Brasileira de Letras, “O termo carochinha, atrelado à imagem de uma velha bondosa e afável a distrair os pequenos com suas narrativas feéricas, foi introduzido no nosso folclore através da obra Histórias da Carochinha, uma coleção de textos oriundos da tradição oral, organizada por Figueiredo Pimentel e que veio a ser o primeiro livro infantil publicado no Brasil, depois de 1920, para acalentar as crianças.” https://www.academia.org.br/artigos/historias-da-carochinha↩︎\n",
            "https://github.com/SheilaCastilho/DELA-Project↩︎\n",
            "Tradução fornecida pela profa. Adriana Pagano. O contexto da frase é esse: Some people have to give up drinking completely, they can’t have a couple because they know where it would lead. Alcoholism is real. It requires a serious, courageous ongoing recovery process. That feels separate to what I’m describing here. I had fallen into grey-area drinking, a term coined by Jolene Park, that describes the feeling that you don’t have a “drinking problem”, but you do have a “problem with drinking” without it being a severe alcohol use disorder.↩︎\n",
            "Na linguagem cotidiana, “simplificar um texto” pode ser sinônimo de “resumir um texto”. Em PLN e outras áreas do conhecimento, entretanto, as tarefas de “sumarização” e “simplificação” são diferentes, ainda que haja sobreposições.↩︎\n",
            "Você também pode ver a resposta em https://g.co/bard/share/b6fd7a5a8d53.↩︎\n",
            "https://cdn.openai.com/snapshot-of-chatgpt-model-behavior-guidelines.pdf↩︎\n",
            "Este tópico (“Compositoras brasileiras de samba”) foi um dos 150 tópicos utilizados na avaliação conjunta Págico, realizada em 2012. O Págico teve como objetivo avaliar a capacidade dos sistemas de encontrar respostas a necessidades de informação complexas, considerando exclusivamente a Wikipédia de língua portuguesa como fonte das informações. Como é possível imaginar, foi uma tarefa muito difícil para a época, e os sistemas tiveram um desempenho muito ruim. No entanto, todo o material usado – uma lista com 150 tópicos/perguntas, as respostas corretas, um retrato da Wikipédia em português de abril de 2012 e medidas de avaliação, entre outros – está disponível na página do Págico https://www.linguateca.pt/aval_conjunta/Pagico/index.html e https://www.linguateca.pt/Cartola/, página dedicada apenas aos recursos criados. Uma apresentação do Págico, bem como discussão dos resultados e das participações, foi publicada em uma edição especial da revista Linguamática https://linguamatica.com/index.php/linguamatica/issue/view/8↩︎\n",
            "Você também pode ver a resposta em https://g.co/bard/share/2b9538605f13.↩︎\n",
            "https://ai.google/static/documents/google-about-bard.pdf↩︎\n",
            "https://blog.google/technology/ai/lamda/↩︎\n",
            "Você também pode ver a resposta em https://g.co/bard/share/f7b5eefcbfec.↩︎\n",
            "A palestra ChatGPT: O que é? De onde veio? Para onde vamos?, do grupo Brasileiras em PLN (https://youtu.be/F8yxBbx8woU?si=MfcBoV_tWhde-njy), embora tenha exemplos de uso do ChatGPT que já ficaram obsoletos, explora alguns limites do uso desses agentes como oráculo, além de fazer uma apresentação de como esses modelos como GPT são criados.↩︎\n",
            "Veja-se por exemplo http://www.uol.com.br/tilt/reportagens-especiais/a-vida-dura-de-quem-treina-inteligencias-artificiais/ e Seção 14.4.5↩︎\n",
            "Água doce é necessária para resfriar os super-processadores.↩︎\n",
            "https://oglobo.globo.com/economia/tecnologia/noticia/2023/05/treino-do-chatgpt-consumiu-700-mil-litros-de-agua-equivalente-a-encher-uma-torre-de-resfriamento-de-um-reator-nuclear.ghtml ou https://www.printfriendly.com/p/g/D56wCg↩︎\n",
            "\n",
            " CAPITULO 5 \n",
            "Fogo de palha ou osso duro de roer?\n",
            "Renata Ramisch \n",
            "Carlos Ramisch \n",
            "Aline Villavicencio \n",
            "26/09/2023\n",
            "PDF\n",
            "O capítulo sobre as expressões multipalavras, que sairá na próxima edição deste livro, vai abordar um tema indigesto no universo no Processamento de Linguagem Natural (PLN). É que essas expressões ficam no limite entre a sintaxe e a semântica, e sempre acabam ficando no meio do fogo cruzado. De um lado, elas apresentam idiossincrasias e especificidades que não permitem determinadas operações sintáticas comuns a outros conjuntos de palavras. De outro, as definições do sentido das expressões multipalavras (ou MWEs) em geral fogem à regra de que o significado do todo se dá pela soma das partes. Ainda bem, pois imagine se a expressão “engolir o sapo” fosse literal.\n",
            "Assim, a nossa intenção para este capítulo é, em primeiro lugar, definir quais são os conceitos fundamentais para quem vai navegar pelas águas turbulentas do tratamento computacional de MWEs. Entre esses conceitos, começaremos com a discussão sobre os elementos que compõem uma MWE: seriam palavras? Seriam lexemas?\n",
            "Na sequência, abordaremos os conceitos de MWEs propriamente ditos. A literatura traz inúmeras maneiras de analisar essas expressões, e as definições são tão variadas quanto os campos de estudo que se interessam por esse tema. Em PLN, escolhemos a definição utilizada pelo projeto PARSEME (o qual também é apresentado brevemente no capítulo que está por vir):\n",
            "Expressões multipalavras são entendidas como sequências (contínuas ou descontínuas) de palavras que (i) contêm pelo menos duas palavras componentes que são lexicalizadas, ou seja, sempre realizadas pelos mesmos lexemas, incluindo uma palavra principal e pelo menos uma outra palavra sintaticamente relacionada, e (ii) exibem algum grau de idiossincrasia lexical, morfológica, sintática e/ou semântica.\n",
            "Considerando essa definição inicial de MWE, vamos pormenorizar alguns dos seus aspectos importantes, como idiossincrasias, coesão sintática e elementos lexicalizados. Ao mesmo tempo, também buscamos separar o joio do trigo, uma vez que, para entender o que é uma MWE, é fundamental que se saiba também o que ela não é. Então, explicaremos por que, na nossa abordagem, os compostos, as colocações e as metáforas não são expressões multipalavras.\n",
            "Embora esta seja uma tarefa em aberto, apresentaremos, no nosso futuro capítulo, uma tentativa de classificação de MWEs. O grupo de expressões cujo núcleo é um verbo foi definido nas diretrizes de anotação do PARSEME, e nós basicamente utilizamos as definições desse projeto. No que se refere às demais categorias, consideramos uma série de aspectos práticos e teóricos na nossa proposta de categorização, levando em conta sobretudo a sua função em uma sentença. Traremos, ainda, algumas discussões sobre ambiguidade, variabilidade e arbitrariedade.\n",
            "Após a etapa de conceituações, citaremos as principais tarefas de PLN que envolvem MWEs, assim como o estado da arte, os métodos e algoritmos que buscam resolver esse problema. Essas tarefas se dividem basicamente em dois grandes grupos: a) a descoberta/detecção; e b) a identificação de MWEs.\n",
            "Você verá no capítulo, ainda, uma breve apresentação dos recursos existentes para o português brasileiro, assim como o conhecimento necessário para entender ou resolver alguma tarefa em torno da questão das MWEs. Depois, trataremos dos principais métodos de avaliação, assim como métricas e testes comumente utilizados pela comunidade para avaliar o desempenho de métodos e algoritmos direcionados a tratar ou resolver as tarefas antes mencionadas.\n",
            "Por fim, consideramos importante olhar pelo retrovisor e entender qual foi o percurso para chegar até onde estamos, no tema das MWEs, em termos científicos, na direção da resolução dessa complexa tarefa. Em que ponto estamos hoje? Qual é a posição do português brasileiro em termos de recursos e de pesquisas diante da comunidade internacional? Quais são os desafios que permanecem aos pesquisadores e entusiastas das MWEs para descascar esse abacaxi em tempos de modelos de língua tão grandes que não cabem em si?\n",
            "Sem querer prometer mundos e fundos, o capítulo que está por vir tentará acrescentar mais um tijolo na construção do conhecimento linguístico em PLN para o português brasileiro. Como você pôde perceber por este resumo, o capítulo contém uma série de exemplos de expressões multipalavras, tanto para ilustrar fenômenos linguísticos quanto para divertir leitores e leitoras. Vale a pena esperar pelas cenas do nosso próximo capítulo!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "openai.api_key = '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'#os.getenv(\"OPENAI_API_KEY\")\n",
        "\n"
      ],
      "metadata": {
        "id": "c1_za8-aagBO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = \"\"\n",
        "for i in range(5):\n",
        "  x=math.ceil(len(texto)/5)*i\n",
        "  y=math.ceil(len(texto)/5)*(i+1)\n",
        "  out += texto[x:y]\n",
        "  print(i)\n",
        "print(len(out))\n",
        "len(texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzuqITq1gCqw",
        "outputId": "896ca18a-612d-4be5-d15a-13f28b027923"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "52552\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52552"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sumarização de texto"
      ],
      "metadata": {
        "id": "PKlt6hfIdjU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = \"text-davinci-003\"\n",
        "\n",
        "\n",
        "endpoint = \"https://api.openai.com/v1/engines/\" + modelo + \"/completions\"\n",
        "\n",
        "out = \"\"\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  x=math.ceil(len(texto)/5)*i\n",
        "  y=math.ceil(len(texto)/5)*(i+1)\n",
        "\n",
        "\n",
        "  parametros = {\n",
        "      \"prompt\": \"Faça um resumo do seguinte texto: \" + texto[x:y],\n",
        "      \"temperature\": 0.7,\n",
        "      \"max_tokens\": 40\n",
        "  }\n",
        "  headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "  }\n",
        "\n",
        "\n",
        "  resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "  time.sleep(15)\n",
        "\n",
        "  print(resposta.json()[\"choices\"][0][\"text\"].strip())\n",
        "\n",
        "\n",
        "  time.sleep(5)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBfwSDcqa610",
        "outputId": "5fbe9c35-6755-4745-f637-8e62c0da859e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atividades, mas não tão bons em outras.\n",
            "\n",
            "Resumo: ChatGPT e Maritalk são exemplos de aplicações de\n",
            "olhemos o poema “A Vida é Curta”, de Vinícius de Moraes31, com o seguinte prompt:\n",
            "\n",
            "A Figura\n",
            "“avó” ou “avó Lili” no livro. Ela é uma senhora muito sábia e bondosa, que ent\n",
            "de elementos não relacionados”.↩︎\n",
            "https://www.nature.com/articles/s41586-020-03191-3↩\n",
            "Este capítulo aborda as expressões multipalavras (MWEs), que estão no limite entre a sintaxe e a semâ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Palavra - Chave"
      ],
      "metadata": {
        "id": "sDOF9fDaasXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = \"text-davinci-003\"\n",
        "\n",
        "\n",
        "endpoint = \"https://api.openai.com/v1/engines/\" + modelo + \"/completions\"\n",
        "\n",
        "out = \"\"\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  x=math.ceil(len(texto)/5)*i\n",
        "  y=math.ceil(len(texto)/5)*(i+1)\n",
        "\n",
        "\n",
        "  parametros = {\n",
        "      \"prompt\": \"Extraia 2 palavras-chaves do texto: \" + texto[x:y],\n",
        "      \"temperature\": 0.7,\n",
        "      \"max_tokens\": 40\n",
        "  }\n",
        "  headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "  }\n",
        "\n",
        "\n",
        "  resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "  time.sleep(15)\n",
        "  print(resposta.json()[\"choices\"][0][\"text\"].strip())\n",
        "  time.sleep(5)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi7_fmYDj2Cq",
        "outputId": "25c9b033-5729-4e1c-be53-37d21c21761b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atividades (digamos, prever próximas palavras ou encadear palavras para formar frases), mas não tão bons em\n",
            "olhemos o seguinte texto em português:\n",
            "\n",
            "Palavras-chave: Interação, Linguagem, Modelos, Previs\n",
            "“avó” ou “vovó” no livro. Ela é uma mulher idosa e inteligente, que vive numa faz\n",
            "de relações inexistentes”.↩︎\n",
            "https://www.openai.com/blog/chat-safety-and-fairness/↩\n",
            "Palavras-chaves: Expressões Multipalavras, PLN, Idiossincrasias, Coesão Sintática, Elementos Lexical\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correção Gramatical"
      ],
      "metadata": {
        "id": "4RmL6X9ta4tO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P5f-7MgKayib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = \"text-davinci-003\"\n",
        "\n",
        "\n",
        "endpoint = \"https://api.openai.com/v1/engines/\" + modelo + \"/completions\"\n",
        "\n",
        "out = \"\"\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  x=math.ceil(len(texto)/5)*i\n",
        "  y=math.ceil(len(texto)/5)*(i+1)\n",
        "\n",
        "\n",
        "  parametros = {\n",
        "      \"prompt\": \"Faça a Correção Gramatical do texto: \" + texto[x:y],\n",
        "      \"temperature\": 0.7,\n",
        "      \"max_tokens\": 40\n",
        "  }\n",
        "  headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "  }\n",
        "\n",
        "\n",
        "  resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "  time.sleep(15)\n",
        "  print(resposta.json()[\"choices\"][0][\"text\"].strip())\n",
        "  time.sleep(5)\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VCFEKK0aqFd",
        "outputId": "f883839b-b925-4128-d750-945b88c4ec32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "práticas, mas ainda não são adequados para outras.\n",
            "\n",
            "Correção Gramatical: \n",
            "Capítulo 20 \n",
            "Um retrato\n",
            "olhemos uma frase um pouco mais difícil, do poema “A Primavera”, de Vinícius de Moraes,\n",
            "“avó” ou “dona Júlia” no livro. Ela é uma mulher alegre, inteligente e divertida, que\n",
            "de nada.”\n",
            "https://www.nature.com/articles/d41586-019-02377-6↩︎\n",
            "https://textgen.openai.\n",
            "Correção Gramatical do texto:\n",
            "Fogo de palha ou osso duro de roer?\n",
            "Renata Ramisch \n",
            "Carlos Ramisch\n",
            "\n"
          ]
        }
      ]
    }
  ]
}