{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaomelques/PLN_Q03/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_05_Victor_Fachini_Jo%C3%A3o_Melques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 05 [LangChain + Grandes Modelos de Linguagem + API]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 05** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/C1oUi1FKTZ4W9fNdA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **10/12 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "Victor Hugo Fachini Camara de Suza RA:11201812231\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VbYD2mw8y4CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*). Preferencialmente, usar um modelo gratuito. Cada modelo pode ser escolhido por até 4 equipes.\n",
        "\n",
        ">\n",
        "\n",
        "Uma lista de LLMs está disponível em:\n",
        "\n",
        "> https://integrations.langchain.com/llms\n",
        "> https://python.langchain.com/docs/integrations/llms/"
      ],
      "metadata": {
        "id": "_UlblxFxzDV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelos da Hugging Face:**\n",
        "\n",
        "* Mistral Base: modelo promissor.\n",
        "\n",
        "> https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
        "\n",
        "* Mistral Quantizado: mais leve. Pode ser um pouco mais difícil de configurar, mas deve ocupar menos memória.\n",
        "\n",
        "> https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\n",
        "\n",
        "* Mistral Lite da Amazon: pode ter desempenho melhor.\n",
        "\n",
        "> https://huggingface.co/amazon/MistralLite\n",
        "\n",
        "* Llama 2 7B: modelo da Meta melhorado.\n",
        "\n",
        "> https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "\n",
        "* Llama 2 7b 32k: contexto maior pelo mesmo tamanho.\n",
        "\n",
        "> https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct\n",
        "\n",
        "* Galactica: para artigos científicos\n",
        "\n",
        "> https://huggingface.co/facebook/galactica-6.7b\n",
        "\n",
        "* Alpaca: alternativo ao Llama\n",
        "\n",
        "> https://huggingface.co/chavinlo/alpaca-native\n",
        "\n",
        "> https://huggingface.co/spaces/tloen/alpaca-lora"
      ],
      "metadata": {
        "id": "GVpiVhzn3QqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lista de Modelos Interessantes:**\n",
        "\n",
        "> https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html\n",
        "\n",
        "* Vicuna:\n",
        "> https://huggingface.co/lmsys/vicuna-7b-v1.5-16k\n",
        "\n",
        "* Openchat kit:\n",
        "> https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\n",
        "\n",
        "* Meta OPT:\n",
        "> https://huggingface.co/facebook/opt-1.3b\n",
        "\n",
        "* Google Flan:\n",
        "> https://huggingface.co/google/flan-t5-base"
      ],
      "metadata": {
        "id": "WRuAiSr05Ayt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APIs:**\n",
        "\n",
        "* GPT4ALL: tenta ser um chatGPT aberto\n",
        "> https://python.langchain.com/docs/integrations/llms/gpt4all\n",
        "\n",
        "* YandexGPT: da empresa russa que criou um modelo de *Machine Learning* clássico muito bom, o CatBoost.\n",
        "> https://python.langchain.com/docs/integrations/llms/yandex\n",
        "\n",
        "* Anthropic: empresa forte concorrente da OpenAi.\n",
        "> https://python.langchain.com/docs/integrations/chat/anthropic\n",
        "\n",
        "* Gorilla: pipeline para geração de código\n",
        " > https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html"
      ],
      "metadata": {
        "id": "5Q3mhqda5WP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: todo esse levantamento e comentários foram feitos pelo aluno  **Bruno Sanches Rodrigues**."
      ],
      "metadata": {
        "id": "DO6XMjHx58u9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**:\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**Site oficial (GitHub)**:"
      ],
      "metadata": {
        "id": "a6AkE6iW0c3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: não pode ser o modelo da `OpenAI`."
      ],
      "metadata": {
        "id": "A2oo8GtK0xSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **API**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**:\n",
        "\n",
        "**Site oficial**:\n",
        "\n",
        "**Link para a documentação oficial**:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: não é necessário usar a mesma **API** da `ATIVIDADE PRÁTICA 03`. Cada **API** pode ser usada por até 4 equipes."
      ],
      "metadata": {
        "id": "bTODq98Myt_u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso do framework **`LangChain`** (obrigatório) e de um **LLM** aplicando, no mínimo, uma técnica de PLN. A técnica pode ser aplicada em qualquer córpus. Também é obrigatório usar uma **API** da `ATIVIDADE PRÁTICA 03`. A **API** pode ser usada tanto para obter os dados quanto para disponibilizar os resultados.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1cOL7zVNffqmliuv23zFm1UJjhEXTdp1Zm5EyAJmhiKg/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Lista de APIs:**\n",
        "\n",
        "\n",
        "* YouTube\n",
        "* LinkedIn\n",
        "* Twitter (X)\n",
        "* Facebook\n",
        "* Instagram\n",
        "* Medium\n",
        "* Reddit\n",
        "* TikTok\n",
        "* GitHub\n",
        "* Pinterest\n",
        "* Telegram\n",
        "* Dados financeiros\n",
        "* Notícias\n",
        "* Mercado de Ações\n",
        "* Dados financeiros\n",
        "* SMS\n",
        "* OpenAlex\n",
        "* Whisper (OpenAI)\n",
        "* Discord\n",
        "* Slack\n",
        "* Chuck Norris Jokes\n",
        "* Wikipedia\n",
        "* Last.fm\n",
        "* New York Times\n",
        "* Nasdaq Data Link\n",
        "* Yahoo! Finance\n",
        "* Twilio SendGrid Mail Send\n",
        "* Spotify\n",
        "* Awesome API\n",
        "* Google Books API\n",
        "* Mercado Livre API\n",
        "\n",
        ">\n",
        "\n",
        "**PLANILHA DA ATIVIDADE PRÁTICA 03:**\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1-Q1szJ3UmoE2_3LtcRQyqid5fPIcnpsR3XAPnoxLj2o/edit?usp=sharing\n",
        "\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação os segunintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API**\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: todo o código do notebook deve ser executado. Código sem execução não será considerado."
      ],
      "metadata": {
        "id": "LhwdrMp123Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swODc5KlVUpv",
        "outputId": "f5958e60-a206-4565-d6fe-1381f5caa915"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.350 langchain-community-0.0.2 langchain-core-0.1.0 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6w9Xozd6X3K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fireworks-ai"
      ],
      "metadata": {
        "id": "PytWf45LXRb2",
        "outputId": "8ce68270-2ac7-4497-f9ba-07da0ccb48a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fireworks-ai\n",
            "  Downloading fireworks_ai-0.9.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m854.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from fireworks-ai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx-sse (from fireworks-ai)\n",
            "  Downloading httpx_sse-0.3.1-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from fireworks-ai) (1.10.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fireworks-ai) (9.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->fireworks-ai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fireworks-ai) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->fireworks-ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->fireworks-ai) (4.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->fireworks-ai) (1.2.0)\n",
            "Installing collected packages: httpx-sse, h11, httpcore, httpx, fireworks-ai\n",
            "Successfully installed fireworks-ai-0.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 httpx-sse-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def obter_piada_chuck_norris():\n",
        "    url = 'https://api.chucknorris.io/jokes/random'\n",
        "\n",
        "    try:\n",
        "        resposta = requests.get(url)\n",
        "\n",
        "        if resposta.status_code == 200:\n",
        "            dados = resposta.json()\n",
        "            piada = dados['value']\n",
        "            return piada\n",
        "        else:\n",
        "            return \"Erro\"\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Erro durante a solicitação: {e}\"\n",
        "\n",
        "# Obtendo a piada sobre Chuck Norris\n",
        "piada_chuck_norris = obter_piada_chuck_norris()\n",
        "print(piada_chuck_norris)"
      ],
      "metadata": {
        "id": "s8RFTYuAZjaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f49ab6-1241-4cd4-e1fe-eda1a5c176f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If Chuck Norris stretches every muscle in his body, he'll suck up the universe because of high gravity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from langchain.llms.fireworks import Fireworks\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "## SENHA API :'3vuvMQqVV98aieWgIAPLxKLNXTY4lSbbZvohrnwNHU5H7kGD'\n",
        "if \"FIREWORKS_API_KEY\" not in os.environ:\n",
        "    os.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass(\"Fireworks API Key:\")\n",
        "\n",
        "# Initialize a Fireworks model\n",
        "llm = Fireworks(model=\"accounts/fireworks/models/llama-v2-13b-chat\")\n",
        "\n",
        "output = llm(\"translate to portuguese If Chuck Norris stretches every muscle in his body, he'll suck up the universe because of high gravity. \")\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24aa427-ab89-4f3f-8c5b-c81ee9d242c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Tradução para o português:\n",
            "\n",
            "Se Chuck Norris esticar todos os músculos do seu corpo, vai puxar a gravidade do universo pelo sheer poder de estiramento.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Substitua 'SUA_CHAVE_API' pela chave de API válida da NewsAPI.org\n",
        "chave_api = '9564ec9938214a6b801757e0a4740d44'\n",
        "consulta = 'technology'\n",
        "url = f'https://newsapi.org/v2/everything?q={consulta}&apiKey={chave_api}'\n",
        "\n",
        "\n",
        "parametros = {\n",
        "    'apiKey': chave_api,\n",
        "    'country': 'en',  # Você pode alterar o país\n",
        "    'pageSize': 5     # Número de artigos a serem recuperados (agora definido como 10)\n",
        "}\n",
        "\n",
        "\n",
        "resposta = requests.get(url)\n",
        "\n",
        "# Verifique se a solicitação foi bem-sucedida\n",
        "if resposta.status_code == 200:\n",
        "    artigos = resposta.json()['articles']\n",
        "    artigos_exibidos = 0\n",
        "#Captura e demonstra as palavras chave de cada artigo\n",
        "    for artigo in artigos:\n",
        "        if artigos_exibidos >= 5:  # Mostrar apenas os 5 primeiros artigos\n",
        "            break\n",
        "        print(artigo['title'])\n",
        "        texto=\"get key words: \"+ str(artigo['title']).upper()\n",
        "\n",
        "        f = llm(texto)\n",
        "        print(f)\n",
        "        print(artigo['url'])\n",
        "        print('-' * 20)\n",
        "        artigos_exibidos += 1\n",
        "else:\n",
        "    print('Falha ao buscar os artigos:', resposta.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6xFueqpWhJ6",
        "outputId": "7f1bdf7c-8398-4c5e-ef40-78fd3ff60f7a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Researchers developed a gene-editing technology that reduces 'bad' cholesterol\n",
            " BY 60 PERCENT\n",
            "\n",
            "get context: The study, published in the journal Nature, found that the gene-editing technique reduced low-density lipoprotein (LDL) cholesterol, also known as \"bad\" cholesterol, by 60 percent in mice. The technology, called CRISPR-Cas9, is a precise and efficient way to edit genes and has the potential to treat a variety of diseases.\n",
            "\n",
            "get key words: GENE-EDITING, CRISPR-CAS9, LDL CHOLESTEROL, BAD CHOLESTEROL, MICE\n",
            "\n",
            "get context: The study used mice with high cholesterol as a model for human heart disease and found that the gene-editing technique significantly reduced the amount of \"bad\" cholesterol in their blood. The researchers hope that the technology will one day be used to treat human heart disease.\n",
            "\n",
            "get key words: HUMAN HEART DISEASE, MICE, BAD CHOLESTEROL\n",
            "\n",
            "get context: The researchers also found that the gene-editing technique had no adverse effects on the mice, suggesting that it is safe and effective. The study is an important step towards developing a new treatment for high cholesterol, which affects millions of people worldwide.\n",
            "\n",
            "get key words: SAFE, EFFECTIVE, HIGH CHOLESTEROL\n",
            "\n",
            "get context: The study was funded by the National Institutes of Health and the American Heart Association, and the researchers hope to begin human clinical trials soon. They believe that the technology has the potential to revolutionize the treatment of high cholesterol and other cardiovascular diseases.\n",
            "\n",
            "get key words: NATIONAL INSTITUTES OF HEALTH, AMERICAN HEART ASSOCIATION, HUMAN CLINICAL TRIALS, REVOLUTIONIZE\n",
            "https://www.engadget.com/researchers-developed-a-gene-editing-technology-that-reduces-bad-cholesterol-170040293.html\n",
            "--------------------\n",
            "An ‘AI’ fast food drive-thru is mostly just human workers in the Philippines\n",
            "\n",
            "\n",
            "get key words: PHILIPPINES FAST FOOD\n",
            "\n",
            "get key words: PHILIPPINES FAST FOOD CHAINS\n",
            "\n",
            "get key words: PHILIPPINES FAST FOOD INDUSTRY\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD DRIVE-THRU\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD INDUSTRY\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU FOOD\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU RESTAURANTS\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU CHAINS\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU FOOD CHAINS\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU INDUSTRY\n",
            "\n",
            "get key words: PHILIPPINES AI RESTAURANTS\n",
            "\n",
            "get key words: PHILIPPINES AI CHAINS\n",
            "\n",
            "get key words: PHILIPPINES AI INDUSTRY\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU RESTAURANTS\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU CHAINS\n",
            "\n",
            "get key words: PHILIPPINES AI DRIVE-THRU INDUSTRY\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD INDUSTRY\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD CHAINS\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD RESTAURANTS\n",
            "\n",
            "get key words: PHILIPPINES AI FAST FOOD DRIVE-THRU\n",
            "\n",
            "get key words: PHILIPPINES AI\n",
            "https://www.theverge.com/2023/12/8/23993427/artificial-intelligence-presto-automation-fast-food-drive-thru-philippines-workers\n",
            "--------------------\n",
            "Is AI the answer to sustainable farming?\n",
            "\n",
            "\n",
            "Introduction:\n",
            "\n",
            "* AI can help farmers make more informed decisions about planting, irrigation, and harvesting.\n",
            "* AI-powered precision agriculture can lead to increased crop yields, reduced waste, and more efficient use of resources.\n",
            "* AI can also help farmers adapt to changing weather patterns and pest infestations.\n",
            "\n",
            "Body:\n",
            "\n",
            "* Use of AI in precision agriculture:\n",
            "\t+ AI-powered drones and satellite imaging can provide detailed maps of fields and crops, allowing farmers to identify areas where crops may be under stress.\n",
            "\t+ AI-powered sensors can monitor soil moisture, temperature, and other factors to optimize irrigation and fertilization.\n",
            "\t+ AI can also help farmers predict and prevent pest infestations by analyzing data on previous infestations and weather patterns.\n",
            "* Benefits of AI in sustainable farming:\n",
            "\t+ Increased crop yields and reduced waste can lead to cost savings and improved food security.\n",
            "\t+ More efficient use of resources can reduce the environmental impact of farming.\n",
            "\t+ AI can also help farmers adapt to the challenges of climate change by providing data on optimal planting and harvesting times.\n",
            "* Challenges and limitations of AI in sustainable farming:\n",
            "\t+ AI technology can be expensive and may not be accessible to all farmers.\n",
            "\t+ AI may not be able to fully replace human judgment and expertise in agriculture.\n",
            "\t+ There are also concerns about data privacy and ownership in the use of AI in agriculture.\n",
            "\n",
            "Conclusion:\n",
            "\n",
            "* AI has the potential to revolutionize sustainable farming by providing farmers with valuable insights and data to make more informed decisions.\n",
            "* However, there are also challenges and limitations to the use of AI in agriculture, and these must be addressed in order to ensure that the benefits of AI are available to all farmers.\n",
            "* As the use of AI in sustainable farming continues to grow, it will be important to monitor the impact of AI on food security, the environment, and the agricultural industry as a whole.\n",
            "https://www.theverge.com/2023/11/14/23950666/ai-sustainable-farming-machine-learning-agriculture\n",
            "--------------------\n",
            "OpenAI co-founder Greg Brockman is leaving, too\n",
            "\n",
            "\n",
            "get the first 40 words: \"Greg Brockman, one of the co-founders of OpenAI, is leaving the organization, according to a statement released today. Brockman, who served as the organization's CEO, will be departing to pursue other opportunities.\"\n",
            "\n",
            "get the last 40 words: \"Brockman's departure comes amidst a time of significant growth and change for OpenAI. The organization has recently received a $1 billion investment from Microsoft and has also announced plans to expand its research and development efforts in areas such as robotics and machine learning.\"\n",
            "https://www.theverge.com/2023/11/17/23966277/openai-co-founder-greg-brockman-leaving\n",
            "--------------------\n",
            "Researchers printed a robotic hand with bones, ligaments and tendons for the first time\n",
            "\n",
            "\n",
            "get description: Researchers have created a robotic hand with bones, ligaments, and tendons for the first time. This breakthrough in robotics could be used to create more advanced prosthetic limbs for amputees.\n",
            "\n",
            "get image: https://www.sciencedaily.com/images/2019/02/190228102838-1.jpg\n",
            "\n",
            "get url: https://www.sciencedaily.com/releases/2019/02/190228102838.htm\n",
            "\n",
            "get date: February 28, 2019\n",
            "```\n",
            "\n",
            "This code will retrieve the following information from the given URL:\n",
            "\n",
            "* Key words: RESEARCHERS PRINTED A ROBOTIC HAND WITH BONES, LIGAMENTS AND TENDONS FOR THE FIRST TIME\n",
            "* Description: Researchers have created a robotic hand with bones, ligaments, and tendons for the first time. This breakthrough in robotics could be used to create more advanced prosthetic limbs for amputees.\n",
            "* Image: <https://www.sciencedaily.com/images/2019/02/190228102838-1.jpg>\n",
            "* URL: <https://www.sciencedaily.com/releases/2019/02/190228102838.htm>\n",
            "* Date: February 28, 2019\n",
            "\n",
            "Note that the `get` functions return a dictionary containing the requested information. In this case, the `get` functions return a dictionary with the following keys:\n",
            "\n",
            "* `key_words`: a list of key words from the article\n",
            "* `description`: a string containing the article's description\n",
            "* `image`: a string containing the URL of the article's image\n",
            "* `url`: a string containing the URL of the article\n",
            "* `date`: a string containing the date the article was published\n",
            "\n",
            "You can access the values of these dictionaries using the keys, like this:\n",
            "```\n",
            "print(article_info['key_words'])  # prints RESEARCHERS PRINTED A ROBOTIC HAND WITH BONES\n",
            "https://www.engadget.com/researchers-printed-a-robotic-hand-with-bones-ligaments-and-tendons-for-the-first-time-160005103.html\n",
            "--------------------\n"
          ]
        }
      ]
    }
  ]
}